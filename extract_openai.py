# Generated by chatgpt on 5th August 2025
import os
import base64
import asyncio
import aiohttp
import aiofiles
import glob
import json
import time
from tqdm import tqdm
from dotenv import load_dotenv
from typing import List

load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = "gpt-4o"
MAX_CONCURRENT_REQUESTS = 5
RETRY_LIMIT = 3
RETRY_BACKOFF = 5  # seconds

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

SYSTEM_PROMPT = (
    "You're a document parser. Given an image of a receipt, "
    "extract structured data in JSON including all leaf-node values and their bounding boxes (x,y,w,h)."
)

async def encode_image(file_path: str) -> str:
    async with aiofiles.open(file_path, "rb") as f:
        img_bytes = await f.read()
    return base64.b64encode(img_bytes).decode("utf-8")

async def call_openai(image_b64: str, session: aiohttp.ClientSession) -> dict:
    payload = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}},
                    {"type": "text", "text": "Please extract the structured JSON for this receipt."}
                ]
            }
        ]
    }

    for attempt in range(RETRY_LIMIT):
        try:
            async with session.post("https://api.openai.com/v1/chat/completions", headers=HEADERS, json=payload) as resp:
                print(resp.content)
                if resp.status == 200:
                    data = await resp.json()
                    return data
                elif resp.status in [429, 502, 503]:
                    await asyncio.sleep(RETRY_BACKOFF * (attempt + 1))
                else:
                    print(f"Non-retryable error: {resp.status}")
                    return None
        except Exception as e:
            print(f"Request failed: {e}")
            await asyncio.sleep(RETRY_BACKOFF * (attempt + 1))
    return None

async def process_image(file_path: str, session: aiohttp.ClientSession, output_dir: str):
    image_b64 = await encode_image(file_path)
    result = await call_openai(image_b64, session)
    
    if result:
        try:
            content = result["choices"][0]["message"]["content"].replace("```json","").replace("```","")
            out_path = os.path.join(output_dir, os.path.basename(file_path) + ".json")
            async with aiofiles.open(out_path, "w") as out_file:
                await out_file.write(content)
        except Exception as e:
            print(f"Parsing error on {file_path}: {e}")
    else:
        print(f"Failed to process {file_path}")

async def worker(file_paths: List[str], output_dir: str):
    connector = aiohttp.TCPConnector(limit_per_host=MAX_CONCURRENT_REQUESTS)
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = [process_image(fp, session, output_dir) for fp in file_paths if not os.path.exists(os.path.join(output_dir, os.path.basename(fp) + ".json"))]
        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks)):
            await f

def get_image_files(input_dir: str):
    return glob.glob(os.path.join(input_dir, "*.jpg")) + glob.glob(os.path.join(input_dir, "*.png"))

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_dir", required=True, help="Directory containing receipt images")
    parser.add_argument("--output_dir", required=True, help="Directory to save output JSONs")
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)
    file_list = get_image_files(args.input_dir)
    print(f"Found {len(file_list)} images. Starting...")

    start = time.time()
    asyncio.run(worker(file_list, args.output_dir))
    print(f"Completed in {time.time() - start:.2f}s")
