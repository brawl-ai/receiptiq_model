{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98eb2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79274c7",
   "metadata": {},
   "source": [
    "# ReceiptIQ Model\n",
    "\n",
    "This is the model behind the receiptiq application. It takes a receipt/invoice image and a json schema and generates the desired output in json format with each JSON leaf containing both the extracted value and the bounding box coordinates in format [x,y,w,h]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572781ac",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The starting dataset is a composite of images only from:\n",
    "- [Receipt or Invoice Computer Vision Model](https://universe.roboflow.com/jakob-awn1e/receipt-or-invoice)\n",
    "- [OCR Receipts Text Detection - retail dataset](https://www.kaggle.com/datasets/trainingdatapro/ocr-receipts-text-detection)\n",
    "- [Receipt Dataset for information extraction](https://www.kaggle.com/datasets/dhiaznaidi/receiptdatasetssd300v2)\n",
    "\n",
    "Totaling `7,334 images` in `datasets/images` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7a420",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "Given this dataset does not natively contain extracted information and importantly the bounding boxes (Some contain data but it's incomplete and mostly doesn't have the bounding information), the raw images were sent through a larger model to distill the high quality training data from the receipts. In this case it is `gpt4o` from openai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49902be",
   "metadata": {},
   "source": [
    "### Model disitilation\n",
    "Sample json file\n",
    "```json\n",
    "{\n",
    "  \"store_info\": {\n",
    "    \"name\": {\n",
    "      \"value\": \"POP TATES R-MALL\",\n",
    "      \"bbox\": [50, 20, 150, 20],\n",
    "      \"descr\": \"Store name\"\n",
    "    },\n",
    "    \"address\": {\n",
    "      \"value\": \"MULUND WEST, MUMBAI - 421 004\",\n",
    "      \"bbox\": [50, 40, 200, 20],\n",
    "      \"descr\": \"Store address\"\n",
    "    },\n",
    "    \"phone\": {\n",
    "      \"value\": \"TEL: 2591 2591\",\n",
    "      \"bbox\": [50, 60, 150, 20],\n",
    "      \"descr\": \"Store phone number\"\n",
    "    }\n",
    "  },\n",
    "  \"transaction_info\": {\n",
    "    \"bill_no\": {\n",
    "      \"value\": \"2708/020612/3V\",\n",
    "      \"bbox\": [50, 100, 150, 20],\n",
    "      \"descr\": \"Bill number\"\n",
    "    }\n",
    "    ...\n",
    "```\n",
    "\n",
    "Having tested on 10 images which took 204s i.e 20s/image:\n",
    "the collection of 7334 images would take `7,334 images * 20 s/image = 146,680 s approx 40hr 45 minutes` which is inefficient.\n",
    "Coupled with the cheaper pricing for batch inference and api rate limits, batch inference is prefered for model distillation.\n",
    "Nonethless, a batch of 500 was used to refine the the rest of the prep and training while full batch was being prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808b6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-5-nano\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You're a document parser. Given an image of a receipt, \"\n",
    "    \"extract structured data in JSON including all leaf-node values and their bounding boxes (x,y,w,h). For the leaf nodes\" \\\n",
    "    \"use the format `name: {{value: actual value, bbox: bounding box in the format (x,y,w,h), descr: description of the field}} \"\n",
    ")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "def get_image_files(input_dir: str):\n",
    "    return glob.glob(os.path.join(input_dir, \"*.jpg\")) + glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "\n",
    "def prepare_batch_files(image_files_list: List[str], output_dir: str, max_items_per_batch: int):\n",
    "    IMAGE_BASE_URL = \"https://receiptiq-model-finetuning-receipts.t3.storageapi.dev\"\n",
    "    shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_count = 0\n",
    "    current_batch = []\n",
    "    batch_files = []\n",
    "    for img_file in tqdm(image_files_list, desc=\"Preparing batch files\"):\n",
    "        file_name = img_file.split(\"/\")[-1]\n",
    "        img_url = f\"{IMAGE_BASE_URL}/{file_name}\"\n",
    "        payload = {\n",
    "            \"custom_id\": img_file,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"image_url\",\"image_url\": {\"url\": img_url}},\n",
    "                            {\"type\": \"text\",\"text\": \"Please extract the structured JSON for this receipt. Respond only in json format of your best approximation.\"}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        current_batch.append(payload)\n",
    "        if len(current_batch) >= max_items_per_batch:\n",
    "            batch_path = os.path.join(output_dir, f\"batch_{batch_count}.jsonl\")\n",
    "            with open(batch_path, \"w\") as f:\n",
    "                for item in current_batch:\n",
    "                    f.write(json.dumps(item) + \"\\n\")\n",
    "            batch_count += 1\n",
    "            current_batch = []\n",
    "            batch_files.append(batch_path)\n",
    "    if current_batch:\n",
    "        batch_path = os.path.join(output_dir, f\"batch_{batch_count}.jsonl\")\n",
    "        batch_files.append(batch_path)\n",
    "        with open(batch_path, \"w\") as f:\n",
    "            for item in current_batch:\n",
    "                f.write(json.dumps(item) + \"\\n\")\n",
    "    return batch_files\n",
    "\n",
    "def upload_batch_file(filepath: str):\n",
    "    \"\"\"Upload a JSONL file for batch processing\"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        resp = client.files.create(file=f, purpose=\"batch\")\n",
    "    return resp.id\n",
    "\n",
    "def start_batch(file_id: str, batch_name: str, completion_window: str):\n",
    "    \"\"\"Start a batch job from an uploaded file\"\"\"\n",
    "    resp = client.batches.create(\n",
    "        input_file_id=file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=completion_window,\n",
    "        metadata={\"name\": batch_name}\n",
    "    )\n",
    "    return resp.id\n",
    "\n",
    "def wait_for_completion(batch_id: str, poll_interval:int):\n",
    "    \"\"\"Poll until batch is completed or failed\"\"\"\n",
    "    while True:\n",
    "        resp = client.batches.retrieve(batch_id)\n",
    "        status = resp.status\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Batch {batch_id} status: {status}\")\n",
    "        if status in (\"completed\", \"failed\", \"expired\", \"cancelled\"):\n",
    "            return status\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "def load_unprocessed_images(processed_file_path, input_dir):\n",
    "    images_files_list = get_image_files(input_dir)\n",
    "    processed_files = set()\n",
    "    if os.path.exists(processed_file_path):\n",
    "        with open(processed_file_path) as f:\n",
    "            processed_files = set(json.load(f))\n",
    "    return [img for img in images_files_list if img not in processed_files], processed_files\n",
    "\n",
    "def save_processed(processed_set, processed_file_path):\n",
    "    with open(processed_file_path, \"w\") as f:\n",
    "        json.dump(list(processed_set), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df08790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing batch files: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_ITEMS_PER_BATCH = 500\n",
    "INPUT_DIR = \"datasets/images\"\n",
    "BATCHES_OUTPUT_DIR = \"datasets/batch_files\"\n",
    "COMPLETION_WINDOW = \"24h\"\n",
    "POLL_INTERVAL = 60\n",
    "PROCESSED_FILE = \"datasets/processed_images.json\" # tracking file to avoid repetitions during restarts\n",
    "\n",
    "remaining_images, processed_images = load_unprocessed_images(PROCESSED_FILE,INPUT_DIR)\n",
    "batch_files = prepare_batch_files(remaining_images, output_dir=BATCHES_OUTPUT_DIR, max_items_per_batch=MAX_ITEMS_PER_BATCH)\n",
    "\n",
    "for idx, batch_file in enumerate(batch_files, start=1):\n",
    "    file_id = upload_batch_file(batch_file)\n",
    "    print(f\"[✓] Uploaded file {batch_file} → File ID: {file_id}\")\n",
    "\n",
    "    batch_id = start_batch(file_id, f\"receiptiq_distill_batch_{idx}\", completion_window=COMPLETION_WINDOW)\n",
    "    print(f\"[✓] Started batch receiptiq_distill_batch_{idx} → Batch ID: {batch_id}\")\n",
    "\n",
    "    status = wait_for_completion(batch_id, poll_interval=POLL_INTERVAL)\n",
    "    print(f\"[!] Batch receiptiq_distill_batch_{idx} finished with status: {status}\")\n",
    "\n",
    "    if status == \"completed\":\n",
    "        with open(batch_file) as bf:\n",
    "            for line in bf:\n",
    "                data = json.loads(line)\n",
    "                processed_images.add(data[\"custom_id\"])\n",
    "        save_processed(processed_images, processed_file_path=PROCESSED_FILE)\n",
    "        time.sleep(300)\n",
    "    else:\n",
    "        print(f\"[!] Batch failed: receiptiq_distill_batch_{idx}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59df42",
   "metadata": {},
   "source": [
    "### Download Distillation Output\n",
    "- Dowload the output (jsonl)\n",
    "- Try and parse the output as json and `ONLY` accept the the ones that are valid json for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6edeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:45,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404 - {'error': {'message': 'No such File object: file-RXx22D9VdHczqR8qZ5H4rj', 'type': 'invalid_request_error', 'param': 'id', 'code': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:45,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404 - {'error': {'message': 'No such File object: file-7qS7Be5NVspA9kBuLzX8KN', 'type': 'invalid_request_error', 'param': 'id', 'code': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:46,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404 - {'error': {'message': 'No such File object: file-M5BKp5Q5NYnYKXLvEgAg9a', 'type': 'invalid_request_error', 'param': 'id', 'code': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:47,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404 - {'error': {'message': 'No such File object: file-V1ofekdEcGvG18sMDrJ3tz', 'type': 'invalid_request_error', 'param': 'id', 'code': None}}\n",
      "7170 receipts\n",
      "160 failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "receipts_and_data = []\n",
    "faulty_extractions = []\n",
    "for batch in tqdm(client.batches.list()):\n",
    "    if batch.status == \"completed\":\n",
    "        try:\n",
    "            output = client.files.content(batch.output_file_id)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        for receipt in output.text.splitlines():\n",
    "            completion_response_json = json.loads(receipt)\n",
    "            receipt_dict = dict(json.loads(receipt)).get(\"response\").get(\"body\").get(\"choices\")[0]\n",
    "            receipt_data = receipt_dict.get(\"message\").get(\"content\")\n",
    "            try:\n",
    "                parsed_data = json.loads(receipt_data)\n",
    "                with open(f'datasets/data/{completion_response_json.get(\"custom_id\").split(\"/\")[-1]}.json',\"w\") as df:\n",
    "                    df.write(receipt_data)\n",
    "                receipts_and_data.append({\n",
    "                    \"image_filename\": f'{completion_response_json.get(\"custom_id\").split(\"/\")[-1]}',\n",
    "                    \"data\": parsed_data\n",
    "                })\n",
    "            except:\n",
    "                faulty_extractions.append(completion_response_json.get(\"custom_id\").split(\"/\")[-1])\n",
    "print(f\"{len(receipts_and_data)} receipts\")\n",
    "print(f\"{len(faulty_extractions)} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae371872",
   "metadata": {},
   "source": [
    "## Clean and format the data\n",
    "- Try and extract the schema and ONLY accept those that are in the expected schema format for now\n",
    "I expected and requested the schema to be `name: {{value: actual value, bbox: bounding box in the format (x,y,w,h), descr: description of the field}}`\n",
    "with possible child dict and child lists as part of hierarchy.\n",
    "- Remove descr from the data\n",
    "- Convert the list to HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae72728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7170/7170 [00:00<00:00, 410297.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['data', 'image_filename'],\n",
       "     num_rows: 6876\n",
       " }),\n",
       " '{\"company_name\": {\"value\": \"[unreadable]\", \"bbox\": \"(60,40,520,40)\"}, \"store_number\": {\"value\": \"[unreadable]\", \"bbox\": \"(520,20,120,20)\"}, \"date\": {\"value\": \"[unreadable]\", \"bbox\": \"(60,90,180,20)\"}, \"time\": {\"value\": \"[unreadable]\", \"bbox\": \"(250,90,120,20)\"}, \"receipt_id\": {\"value\": \"[unreadable]\", \"bbox\": \"(460,90,180,20)\"}, \"subtotal\": {\"value\": \"[unreadable]\", \"bbox\": \"(500,420,120,20)\"}, \"tax\": {\"value\": \"[unreadable]\", \"bbox\": \"(620,420,120,20)\"}, \"total\": {\"value\": \"[unreadable]\", \"bbox\": \"(500,450,140,20)\"}, \"currency\": {\"value\": \"USD\", \"bbox\": \"(700,450,50,20)\"}, \"items\": [{\"name\": {\"value\": \"[unreadable]\", \"bbox\": \"(60,260,320,20)\"}, \"qty\": {\"value\": \"[unreadable]\", \"bbox\": \"(390,260,40,20)\"}, \"price\": {\"value\": \"[unreadable]\", \"bbox\": \"(430,260,60,20)\"}, \"line_total\": {\"value\": \"[unreadable]\", \"bbox\": \"(500,260,60,20)\"}}]}')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Value, Image as HFImage\n",
    "\n",
    "# Extract schema and only accept those that match the expected schema\n",
    "def get_schema(data: dict):\n",
    "    schema = {}\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, dict):\n",
    "            if \"value\" in v:\n",
    "                schema[k] = f\"string//{v.get('descr', '')}\"\n",
    "            else:\n",
    "                schema[k] = get_schema(v)\n",
    "        elif isinstance(v, list):\n",
    "            schema[k] = [get_schema(v[0]) if len(v)>0 else {}]\n",
    "    return schema\n",
    "\n",
    "receipts_and_data_schema_checked = []\n",
    "for item in tqdm(receipts_and_data):\n",
    "    try:\n",
    "        schema = get_schema(item['data'])\n",
    "        receipts_and_data_schema_checked.append(item)\n",
    "    except Exception as e:\n",
    "        # print(item[\"image_filename\"])\n",
    "        # raise\n",
    "        pass\n",
    "\n",
    "\n",
    "# Remove description `descr` fromt the data\n",
    "def remove_descr(data: dict):\n",
    "    out_data = {}\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, dict):\n",
    "            if \"value\" in v:\n",
    "                vc = v.copy()\n",
    "                vc.pop(\"descr\",None)\n",
    "                out_data[k] = vc\n",
    "            else:\n",
    "                out_data[k] = remove_descr(v)\n",
    "        elif isinstance(v, list):\n",
    "            out_data[k] = [remove_descr(child) for child in v]\n",
    "    return out_data\n",
    "\n",
    "receipts_and_data_cleaned = []\n",
    "for item in receipts_and_data_schema_checked:\n",
    "    data_cleaned = remove_descr(item['data'])\n",
    "    receipts_and_data_cleaned.append({\n",
    "        \"data\": json.dumps(data_cleaned, ensure_ascii=False),\n",
    "        \"image_filename\": f\"datasets/images/{item['image_filename']}\"\n",
    "    })\n",
    "\n",
    "\n",
    "# Convert the list to HF dataset\n",
    "features = Features({\n",
    "    \"image_filename\": Value(\"string\"),\n",
    "    \"data\": Value(\"string\")\n",
    "})\n",
    "receipts_and_data_dataset = Dataset.from_list(receipts_and_data_cleaned, features=features)\n",
    "# receipts_and_data_dataset = receipts_and_data_dataset.cast_column(\"image_filename\", HFImage(decode=True))\n",
    "receipts_and_data_dataset, receipts_and_data_dataset[0][\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7720811",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671ef24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6def9184d06c4ef1b48fe4ab93da7ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['data', 'image_filename', 'input_ids', 'attention_mask', 'output_ids', 'output_attention_mask', 'pixel_values', 'aspect_ratio_ids', 'aspect_ratio_mask'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "from datasets import Sequence, Array4D\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "hf_model_id = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "processor = AutoProcessor.from_pretrained(hf_model_id)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "def tokenize(batch):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    output_ids = []\n",
    "    output_attention_mask = []\n",
    "    pixel_values = []\n",
    "    aspect_ratio_ids = []\n",
    "    aspect_ratio_mask = []\n",
    "\n",
    "    for data_json, image_path in zip(batch[\"data\"], batch[\"image_filename\"]):\n",
    "        image_data = Image.open(image_path)\n",
    "        data_dict = json.loads(data_json)\n",
    "        schema_str = json.dumps(get_schema(data_dict), ensure_ascii=False)\n",
    "\n",
    "        input_tokens = processor(\n",
    "            image_data, f\"<|image|><|begin_of_text|>{schema_str}\", return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        output_tokens = tokenizer(\n",
    "            json.dumps(data_dict, ensure_ascii=False), return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        input_ids.append(input_tokens[\"input_ids\"][0])\n",
    "        attention_mask.append(input_tokens[\"attention_mask\"][0])\n",
    "        output_ids.append(output_tokens[\"input_ids\"][0])\n",
    "        output_attention_mask.append(output_tokens[\"attention_mask\"][0])\n",
    "        pixel_values.append(input_tokens[\"pixel_values\"][0])\n",
    "        aspect_ratio_ids.append(input_tokens[\"aspect_ratio_ids\"][0])\n",
    "        aspect_ratio_mask.append(input_tokens[\"aspect_ratio_mask\"][0])\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"output_ids\": output_ids,\n",
    "        \"output_attention_mask\": output_attention_mask,\n",
    "        \"pixel_values\": pixel_values,  # numpy arrays, not lists\n",
    "        \"aspect_ratio_ids\": aspect_ratio_ids,\n",
    "        \"aspect_ratio_mask\": aspect_ratio_mask,\n",
    "    }\n",
    "\n",
    "features = Features({\n",
    "    \"input_ids\": Sequence(Value(\"int32\")),\n",
    "    \"attention_mask\": Sequence(Value(\"int8\")),\n",
    "    \"output_ids\": Sequence(Value(\"int32\")),\n",
    "    \"output_attention_mask\": Sequence(Value(\"int8\")),\n",
    "    \"pixel_values\": Sequence(Sequence(Sequence(Sequence(Value(\"float32\"))))),\n",
    "    \"aspect_ratio_ids\": Sequence(Value(\"int32\")),\n",
    "    \"aspect_ratio_mask\": Sequence(Value(\"int8\")),\n",
    "})\n",
    "\n",
    "receipts_and_data_dataset = receipts_and_data_dataset.select(range(200)).map(\n",
    "    tokenize, \n",
    "    batched=True,\n",
    "    batch_size=2,\n",
    "    num_proc=2\n",
    ")\n",
    "receipts_and_data_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98647754",
   "metadata": {},
   "source": [
    "## Check Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3e8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReceiptIQModelDataLoader\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m      4\u001b[39m max_len = \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(x)+\u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(receipts_and_data_dataset[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m],receipts_and_data_dataset[\u001b[33m\"\u001b[39m\u001b[33moutput_ids\u001b[39m\u001b[33m\"\u001b[39m])])\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from utils import ReceiptIQModelDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = max([len(x)+len(y) for x,y in zip(receipts_and_data_dataset[\"input_ids\"],receipts_and_data_dataset[\"output_ids\"])])\n",
    "test_dataset = ReceiptIQModelDataLoader(dataset=receipts_and_data_dataset,max_len=max_len, tokenizer=tokenizer)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=1)\n",
    "next(iter(test_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
